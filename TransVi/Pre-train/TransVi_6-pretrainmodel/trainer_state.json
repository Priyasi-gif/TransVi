{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 20.0,
  "eval_steps": 500,
  "global_step": 250000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.04,
      "grad_norm": 0.0,
      "learning_rate": 1.9960000000000002e-05,
      "loss": 0.0,
      "step": 500
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.0,
      "learning_rate": 1.9920000000000002e-05,
      "loss": 0.0,
      "step": 1000
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.0,
      "learning_rate": 1.9880000000000003e-05,
      "loss": 0.0,
      "step": 1500
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.0,
      "learning_rate": 1.9840000000000003e-05,
      "loss": 0.0,
      "step": 2000
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.0,
      "learning_rate": 1.98e-05,
      "loss": 0.0,
      "step": 2500
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.0,
      "learning_rate": 1.976e-05,
      "loss": 0.0,
      "step": 3000
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.0,
      "learning_rate": 1.972e-05,
      "loss": 0.0,
      "step": 3500
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.0,
      "learning_rate": 1.968e-05,
      "loss": 0.0,
      "step": 4000
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.0,
      "learning_rate": 1.9640000000000002e-05,
      "loss": 0.0,
      "step": 4500
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.0,
      "learning_rate": 1.9600000000000002e-05,
      "loss": 0.0,
      "step": 5000
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.0,
      "learning_rate": 1.9560000000000002e-05,
      "loss": 0.0,
      "step": 5500
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.0,
      "learning_rate": 1.9520000000000003e-05,
      "loss": 0.0,
      "step": 6000
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.0,
      "learning_rate": 1.948e-05,
      "loss": 0.0,
      "step": 6500
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.0,
      "learning_rate": 1.944e-05,
      "loss": 0.0,
      "step": 7000
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.0,
      "learning_rate": 1.94e-05,
      "loss": 0.0,
      "step": 7500
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.0,
      "learning_rate": 1.936e-05,
      "loss": 0.0,
      "step": 8000
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.0,
      "learning_rate": 1.932e-05,
      "loss": 0.0,
      "step": 8500
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.0,
      "learning_rate": 1.9280000000000002e-05,
      "loss": 0.0,
      "step": 9000
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.0,
      "learning_rate": 1.9240000000000002e-05,
      "loss": 0.0,
      "step": 9500
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.0,
      "learning_rate": 1.9200000000000003e-05,
      "loss": 0.0,
      "step": 10000
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.0,
      "learning_rate": 1.916e-05,
      "loss": 0.0,
      "step": 10500
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.0,
      "learning_rate": 1.912e-05,
      "loss": 0.0,
      "step": 11000
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.0,
      "learning_rate": 1.908e-05,
      "loss": 0.0,
      "step": 11500
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.0,
      "learning_rate": 1.904e-05,
      "loss": 0.0,
      "step": 12000
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.0,
      "learning_rate": 1.9e-05,
      "loss": 0.0,
      "step": 12500
    },
    {
      "epoch": 1.04,
      "grad_norm": 0.0,
      "learning_rate": 1.896e-05,
      "loss": 0.0,
      "step": 13000
    },
    {
      "epoch": 1.08,
      "grad_norm": 0.0,
      "learning_rate": 1.8920000000000002e-05,
      "loss": 0.0,
      "step": 13500
    },
    {
      "epoch": 1.12,
      "grad_norm": 0.0,
      "learning_rate": 1.8880000000000002e-05,
      "loss": 0.0,
      "step": 14000
    },
    {
      "epoch": 1.16,
      "grad_norm": 0.0,
      "learning_rate": 1.884e-05,
      "loss": 0.0,
      "step": 14500
    },
    {
      "epoch": 1.2,
      "grad_norm": 0.0,
      "learning_rate": 1.88e-05,
      "loss": 0.0,
      "step": 15000
    },
    {
      "epoch": 1.24,
      "grad_norm": 0.0,
      "learning_rate": 1.876e-05,
      "loss": 0.0,
      "step": 15500
    },
    {
      "epoch": 1.28,
      "grad_norm": 0.0,
      "learning_rate": 1.8720000000000004e-05,
      "loss": 0.0,
      "step": 16000
    },
    {
      "epoch": 1.32,
      "grad_norm": 0.0,
      "learning_rate": 1.8680000000000004e-05,
      "loss": 0.0,
      "step": 16500
    },
    {
      "epoch": 1.3599999999999999,
      "grad_norm": 0.0,
      "learning_rate": 1.864e-05,
      "loss": 0.0,
      "step": 17000
    },
    {
      "epoch": 1.4,
      "grad_norm": 0.0,
      "learning_rate": 1.86e-05,
      "loss": 0.0,
      "step": 17500
    },
    {
      "epoch": 1.44,
      "grad_norm": 0.0,
      "learning_rate": 1.8560000000000002e-05,
      "loss": 0.0,
      "step": 18000
    },
    {
      "epoch": 1.48,
      "grad_norm": 0.0,
      "learning_rate": 1.8520000000000002e-05,
      "loss": 0.0,
      "step": 18500
    },
    {
      "epoch": 1.52,
      "grad_norm": 0.0,
      "learning_rate": 1.8480000000000003e-05,
      "loss": 0.0,
      "step": 19000
    },
    {
      "epoch": 1.56,
      "grad_norm": 0.0,
      "learning_rate": 1.8440000000000003e-05,
      "loss": 0.0,
      "step": 19500
    },
    {
      "epoch": 1.6,
      "grad_norm": 0.0,
      "learning_rate": 1.8400000000000003e-05,
      "loss": 0.0,
      "step": 20000
    },
    {
      "epoch": 1.6400000000000001,
      "grad_norm": 0.0,
      "learning_rate": 1.8360000000000004e-05,
      "loss": 0.0,
      "step": 20500
    },
    {
      "epoch": 1.6800000000000002,
      "grad_norm": 0.0,
      "learning_rate": 1.832e-05,
      "loss": 0.0,
      "step": 21000
    },
    {
      "epoch": 1.72,
      "grad_norm": 0.0,
      "learning_rate": 1.828e-05,
      "loss": 0.0,
      "step": 21500
    },
    {
      "epoch": 1.76,
      "grad_norm": 0.0,
      "learning_rate": 1.824e-05,
      "loss": 0.0,
      "step": 22000
    },
    {
      "epoch": 1.8,
      "grad_norm": 0.0,
      "learning_rate": 1.8200000000000002e-05,
      "loss": 0.0,
      "step": 22500
    },
    {
      "epoch": 1.8399999999999999,
      "grad_norm": 0.0,
      "learning_rate": 1.8160000000000002e-05,
      "loss": 0.0,
      "step": 23000
    },
    {
      "epoch": 1.88,
      "grad_norm": 0.0,
      "learning_rate": 1.8120000000000003e-05,
      "loss": 0.0,
      "step": 23500
    },
    {
      "epoch": 1.92,
      "grad_norm": 0.0,
      "learning_rate": 1.8080000000000003e-05,
      "loss": 0.0,
      "step": 24000
    },
    {
      "epoch": 1.96,
      "grad_norm": 0.0,
      "learning_rate": 1.8040000000000003e-05,
      "loss": 0.0,
      "step": 24500
    },
    {
      "epoch": 2.0,
      "grad_norm": 0.0,
      "learning_rate": 1.8e-05,
      "loss": 0.0,
      "step": 25000
    },
    {
      "epoch": 2.04,
      "grad_norm": 0.0,
      "learning_rate": 1.796e-05,
      "loss": 0.0,
      "step": 25500
    },
    {
      "epoch": 2.08,
      "grad_norm": 0.0,
      "learning_rate": 1.792e-05,
      "loss": 0.0,
      "step": 26000
    },
    {
      "epoch": 2.12,
      "grad_norm": 0.0,
      "learning_rate": 1.788e-05,
      "loss": 0.0,
      "step": 26500
    },
    {
      "epoch": 2.16,
      "grad_norm": 0.0,
      "learning_rate": 1.7840000000000002e-05,
      "loss": 0.0,
      "step": 27000
    },
    {
      "epoch": 2.2,
      "grad_norm": 0.0,
      "learning_rate": 1.7800000000000002e-05,
      "loss": 0.0,
      "step": 27500
    },
    {
      "epoch": 2.24,
      "grad_norm": 0.0,
      "learning_rate": 1.7760000000000003e-05,
      "loss": 0.0,
      "step": 28000
    },
    {
      "epoch": 2.2800000000000002,
      "grad_norm": 0.0,
      "learning_rate": 1.7720000000000003e-05,
      "loss": 0.0,
      "step": 28500
    },
    {
      "epoch": 2.32,
      "grad_norm": 0.0,
      "learning_rate": 1.768e-05,
      "loss": 0.0,
      "step": 29000
    },
    {
      "epoch": 2.36,
      "grad_norm": 0.0,
      "learning_rate": 1.764e-05,
      "loss": 0.0,
      "step": 29500
    },
    {
      "epoch": 2.4,
      "grad_norm": 0.0,
      "learning_rate": 1.76e-05,
      "loss": 0.0,
      "step": 30000
    },
    {
      "epoch": 2.44,
      "grad_norm": 0.0,
      "learning_rate": 1.756e-05,
      "loss": 0.0,
      "step": 30500
    },
    {
      "epoch": 2.48,
      "grad_norm": 0.0,
      "learning_rate": 1.752e-05,
      "loss": 0.0,
      "step": 31000
    },
    {
      "epoch": 2.52,
      "grad_norm": 0.0,
      "learning_rate": 1.7480000000000002e-05,
      "loss": 0.0,
      "step": 31500
    },
    {
      "epoch": 2.56,
      "grad_norm": 0.0,
      "learning_rate": 1.7440000000000002e-05,
      "loss": 0.0,
      "step": 32000
    },
    {
      "epoch": 2.6,
      "grad_norm": 0.0,
      "learning_rate": 1.7400000000000003e-05,
      "loss": 0.0,
      "step": 32500
    },
    {
      "epoch": 2.64,
      "grad_norm": 0.0,
      "learning_rate": 1.736e-05,
      "loss": 0.0,
      "step": 33000
    },
    {
      "epoch": 2.68,
      "grad_norm": 0.0,
      "learning_rate": 1.732e-05,
      "loss": 0.0,
      "step": 33500
    },
    {
      "epoch": 2.7199999999999998,
      "grad_norm": 0.0,
      "learning_rate": 1.728e-05,
      "loss": 0.0,
      "step": 34000
    },
    {
      "epoch": 2.76,
      "grad_norm": 0.0,
      "learning_rate": 1.724e-05,
      "loss": 0.0,
      "step": 34500
    },
    {
      "epoch": 2.8,
      "grad_norm": 0.0,
      "learning_rate": 1.72e-05,
      "loss": 0.0,
      "step": 35000
    },
    {
      "epoch": 2.84,
      "grad_norm": 0.0,
      "learning_rate": 1.7160000000000002e-05,
      "loss": 0.0,
      "step": 35500
    },
    {
      "epoch": 2.88,
      "grad_norm": 0.0,
      "learning_rate": 1.7120000000000002e-05,
      "loss": 0.0,
      "step": 36000
    },
    {
      "epoch": 2.92,
      "grad_norm": 0.0,
      "learning_rate": 1.7080000000000002e-05,
      "loss": 0.0,
      "step": 36500
    },
    {
      "epoch": 2.96,
      "grad_norm": 0.0,
      "learning_rate": 1.704e-05,
      "loss": 0.0,
      "step": 37000
    },
    {
      "epoch": 3.0,
      "grad_norm": 0.0,
      "learning_rate": 1.7e-05,
      "loss": 0.0,
      "step": 37500
    },
    {
      "epoch": 3.04,
      "grad_norm": 0.0,
      "learning_rate": 1.696e-05,
      "loss": 0.0,
      "step": 38000
    },
    {
      "epoch": 3.08,
      "grad_norm": 0.0,
      "learning_rate": 1.692e-05,
      "loss": 0.0,
      "step": 38500
    },
    {
      "epoch": 3.12,
      "grad_norm": 0.0,
      "learning_rate": 1.688e-05,
      "loss": 0.0,
      "step": 39000
    },
    {
      "epoch": 3.16,
      "grad_norm": 0.0,
      "learning_rate": 1.684e-05,
      "loss": 0.0,
      "step": 39500
    },
    {
      "epoch": 3.2,
      "grad_norm": 0.0,
      "learning_rate": 1.6800000000000002e-05,
      "loss": 0.0,
      "step": 40000
    },
    {
      "epoch": 3.24,
      "grad_norm": 0.0,
      "learning_rate": 1.6760000000000002e-05,
      "loss": 0.0,
      "step": 40500
    },
    {
      "epoch": 3.2800000000000002,
      "grad_norm": 0.0,
      "learning_rate": 1.672e-05,
      "loss": 0.0,
      "step": 41000
    },
    {
      "epoch": 3.32,
      "grad_norm": 0.0,
      "learning_rate": 1.668e-05,
      "loss": 0.0,
      "step": 41500
    },
    {
      "epoch": 3.36,
      "grad_norm": 0.0,
      "learning_rate": 1.664e-05,
      "loss": 0.0,
      "step": 42000
    },
    {
      "epoch": 3.4,
      "grad_norm": 0.0,
      "learning_rate": 1.66e-05,
      "loss": 0.0,
      "step": 42500
    },
    {
      "epoch": 3.44,
      "grad_norm": 0.0,
      "learning_rate": 1.656e-05,
      "loss": 0.0,
      "step": 43000
    },
    {
      "epoch": 3.48,
      "grad_norm": 0.0,
      "learning_rate": 1.652e-05,
      "loss": 0.0,
      "step": 43500
    },
    {
      "epoch": 3.52,
      "grad_norm": 0.0,
      "learning_rate": 1.648e-05,
      "loss": 0.0,
      "step": 44000
    },
    {
      "epoch": 3.56,
      "grad_norm": 0.0,
      "learning_rate": 1.6440000000000002e-05,
      "loss": 0.0,
      "step": 44500
    },
    {
      "epoch": 3.6,
      "grad_norm": 0.0,
      "learning_rate": 1.64e-05,
      "loss": 0.0,
      "step": 45000
    },
    {
      "epoch": 3.64,
      "grad_norm": 0.0,
      "learning_rate": 1.636e-05,
      "loss": 0.0,
      "step": 45500
    },
    {
      "epoch": 3.68,
      "grad_norm": 0.0,
      "learning_rate": 1.632e-05,
      "loss": 0.0,
      "step": 46000
    },
    {
      "epoch": 3.7199999999999998,
      "grad_norm": 0.0,
      "learning_rate": 1.628e-05,
      "loss": 0.0,
      "step": 46500
    },
    {
      "epoch": 3.76,
      "grad_norm": 0.0,
      "learning_rate": 1.6240000000000004e-05,
      "loss": 0.0,
      "step": 47000
    },
    {
      "epoch": 3.8,
      "grad_norm": 0.0,
      "learning_rate": 1.62e-05,
      "loss": 0.0,
      "step": 47500
    },
    {
      "epoch": 3.84,
      "grad_norm": 0.0,
      "learning_rate": 1.616e-05,
      "loss": 0.0,
      "step": 48000
    },
    {
      "epoch": 3.88,
      "grad_norm": 0.0,
      "learning_rate": 1.612e-05,
      "loss": 0.0,
      "step": 48500
    },
    {
      "epoch": 3.92,
      "grad_norm": 0.0,
      "learning_rate": 1.6080000000000002e-05,
      "loss": 0.0,
      "step": 49000
    },
    {
      "epoch": 3.96,
      "grad_norm": 0.0,
      "learning_rate": 1.6040000000000002e-05,
      "loss": 0.0,
      "step": 49500
    },
    {
      "epoch": 4.0,
      "grad_norm": 0.0,
      "learning_rate": 1.6000000000000003e-05,
      "loss": 0.0,
      "step": 50000
    },
    {
      "epoch": 4.04,
      "grad_norm": 0.0,
      "learning_rate": 1.5960000000000003e-05,
      "loss": 0.0,
      "step": 50500
    },
    {
      "epoch": 4.08,
      "grad_norm": 0.0,
      "learning_rate": 1.5920000000000003e-05,
      "loss": 0.0,
      "step": 51000
    },
    {
      "epoch": 4.12,
      "grad_norm": 0.0,
      "learning_rate": 1.588e-05,
      "loss": 0.0,
      "step": 51500
    },
    {
      "epoch": 4.16,
      "grad_norm": 0.0,
      "learning_rate": 1.584e-05,
      "loss": 0.0,
      "step": 52000
    },
    {
      "epoch": 4.2,
      "grad_norm": 0.0,
      "learning_rate": 1.58e-05,
      "loss": 0.0,
      "step": 52500
    },
    {
      "epoch": 4.24,
      "grad_norm": 0.0,
      "learning_rate": 1.576e-05,
      "loss": 0.0,
      "step": 53000
    },
    {
      "epoch": 4.28,
      "grad_norm": 0.0,
      "learning_rate": 1.5720000000000002e-05,
      "loss": 0.0,
      "step": 53500
    },
    {
      "epoch": 4.32,
      "grad_norm": 0.0,
      "learning_rate": 1.5680000000000002e-05,
      "loss": 0.0,
      "step": 54000
    },
    {
      "epoch": 4.36,
      "grad_norm": 0.0,
      "learning_rate": 1.5640000000000003e-05,
      "loss": 0.0,
      "step": 54500
    },
    {
      "epoch": 4.4,
      "grad_norm": 0.0,
      "learning_rate": 1.5600000000000003e-05,
      "loss": 0.0,
      "step": 55000
    },
    {
      "epoch": 4.44,
      "grad_norm": 0.0,
      "learning_rate": 1.556e-05,
      "loss": 0.0,
      "step": 55500
    },
    {
      "epoch": 4.48,
      "grad_norm": 0.0,
      "learning_rate": 1.552e-05,
      "loss": 0.0,
      "step": 56000
    },
    {
      "epoch": 4.52,
      "grad_norm": 0.0,
      "learning_rate": 1.548e-05,
      "loss": 0.0,
      "step": 56500
    },
    {
      "epoch": 4.5600000000000005,
      "grad_norm": 0.0,
      "learning_rate": 1.544e-05,
      "loss": 0.0,
      "step": 57000
    },
    {
      "epoch": 4.6,
      "grad_norm": 0.0,
      "learning_rate": 1.54e-05,
      "loss": 0.0,
      "step": 57500
    },
    {
      "epoch": 4.64,
      "grad_norm": 0.0,
      "learning_rate": 1.5360000000000002e-05,
      "loss": 0.0,
      "step": 58000
    },
    {
      "epoch": 4.68,
      "grad_norm": 0.0,
      "learning_rate": 1.5320000000000002e-05,
      "loss": 0.0,
      "step": 58500
    },
    {
      "epoch": 4.72,
      "grad_norm": 0.0,
      "learning_rate": 1.5280000000000003e-05,
      "loss": 0.0,
      "step": 59000
    },
    {
      "epoch": 4.76,
      "grad_norm": 0.0,
      "learning_rate": 1.5240000000000001e-05,
      "loss": 0.0,
      "step": 59500
    },
    {
      "epoch": 4.8,
      "grad_norm": 0.0,
      "learning_rate": 1.5200000000000002e-05,
      "loss": 0.0,
      "step": 60000
    },
    {
      "epoch": 4.84,
      "grad_norm": 0.0,
      "learning_rate": 1.516e-05,
      "loss": 0.0,
      "step": 60500
    },
    {
      "epoch": 4.88,
      "grad_norm": 0.0,
      "learning_rate": 1.5120000000000001e-05,
      "loss": 0.0,
      "step": 61000
    },
    {
      "epoch": 4.92,
      "grad_norm": 0.0,
      "learning_rate": 1.5080000000000001e-05,
      "loss": 0.0,
      "step": 61500
    },
    {
      "epoch": 4.96,
      "grad_norm": 0.0,
      "learning_rate": 1.5040000000000002e-05,
      "loss": 0.0,
      "step": 62000
    },
    {
      "epoch": 5.0,
      "grad_norm": 0.0,
      "learning_rate": 1.5000000000000002e-05,
      "loss": 0.0,
      "step": 62500
    },
    {
      "epoch": 5.04,
      "grad_norm": 0.0,
      "learning_rate": 1.496e-05,
      "loss": 0.0,
      "step": 63000
    },
    {
      "epoch": 5.08,
      "grad_norm": 0.0,
      "learning_rate": 1.4920000000000001e-05,
      "loss": 0.0,
      "step": 63500
    },
    {
      "epoch": 5.12,
      "grad_norm": 0.0,
      "learning_rate": 1.4880000000000002e-05,
      "loss": 0.0,
      "step": 64000
    },
    {
      "epoch": 5.16,
      "grad_norm": 0.0,
      "learning_rate": 1.4840000000000002e-05,
      "loss": 0.0,
      "step": 64500
    },
    {
      "epoch": 5.2,
      "grad_norm": 0.0,
      "learning_rate": 1.48e-05,
      "loss": 0.0,
      "step": 65000
    },
    {
      "epoch": 5.24,
      "grad_norm": 0.0,
      "learning_rate": 1.4760000000000001e-05,
      "loss": 0.0,
      "step": 65500
    },
    {
      "epoch": 5.28,
      "grad_norm": 0.0,
      "learning_rate": 1.4720000000000001e-05,
      "loss": 0.0,
      "step": 66000
    },
    {
      "epoch": 5.32,
      "grad_norm": 0.0,
      "learning_rate": 1.4680000000000002e-05,
      "loss": 0.0,
      "step": 66500
    },
    {
      "epoch": 5.36,
      "grad_norm": 0.0,
      "learning_rate": 1.464e-05,
      "loss": 0.0,
      "step": 67000
    },
    {
      "epoch": 5.4,
      "grad_norm": 0.0,
      "learning_rate": 1.46e-05,
      "loss": 0.0,
      "step": 67500
    },
    {
      "epoch": 5.44,
      "grad_norm": 0.0,
      "learning_rate": 1.4560000000000001e-05,
      "loss": 0.0,
      "step": 68000
    },
    {
      "epoch": 5.48,
      "grad_norm": 0.0,
      "learning_rate": 1.4520000000000002e-05,
      "loss": 0.0,
      "step": 68500
    },
    {
      "epoch": 5.52,
      "grad_norm": 0.0,
      "learning_rate": 1.448e-05,
      "loss": 0.0,
      "step": 69000
    },
    {
      "epoch": 5.5600000000000005,
      "grad_norm": 0.0,
      "learning_rate": 1.444e-05,
      "loss": 0.0,
      "step": 69500
    },
    {
      "epoch": 5.6,
      "grad_norm": 0.0,
      "learning_rate": 1.4400000000000001e-05,
      "loss": 0.0,
      "step": 70000
    },
    {
      "epoch": 5.64,
      "grad_norm": 0.0,
      "learning_rate": 1.4360000000000001e-05,
      "loss": 0.0,
      "step": 70500
    },
    {
      "epoch": 5.68,
      "grad_norm": 0.0,
      "learning_rate": 1.432e-05,
      "loss": 0.0,
      "step": 71000
    },
    {
      "epoch": 5.72,
      "grad_norm": 0.0,
      "learning_rate": 1.428e-05,
      "loss": 0.0,
      "step": 71500
    },
    {
      "epoch": 5.76,
      "grad_norm": 0.0,
      "learning_rate": 1.4240000000000001e-05,
      "loss": 0.0,
      "step": 72000
    },
    {
      "epoch": 5.8,
      "grad_norm": 0.0,
      "learning_rate": 1.4200000000000001e-05,
      "loss": 0.0,
      "step": 72500
    },
    {
      "epoch": 5.84,
      "grad_norm": 0.0,
      "learning_rate": 1.416e-05,
      "loss": 0.0,
      "step": 73000
    },
    {
      "epoch": 5.88,
      "grad_norm": 0.0,
      "learning_rate": 1.412e-05,
      "loss": 0.0,
      "step": 73500
    },
    {
      "epoch": 5.92,
      "grad_norm": 0.0,
      "learning_rate": 1.408e-05,
      "loss": 0.0,
      "step": 74000
    },
    {
      "epoch": 5.96,
      "grad_norm": 0.0,
      "learning_rate": 1.4040000000000001e-05,
      "loss": 0.0,
      "step": 74500
    },
    {
      "epoch": 6.0,
      "grad_norm": 0.0,
      "learning_rate": 1.4e-05,
      "loss": 0.0,
      "step": 75000
    },
    {
      "epoch": 6.04,
      "grad_norm": 0.0,
      "learning_rate": 1.396e-05,
      "loss": 0.0,
      "step": 75500
    },
    {
      "epoch": 6.08,
      "grad_norm": 0.0,
      "learning_rate": 1.392e-05,
      "loss": 0.0,
      "step": 76000
    },
    {
      "epoch": 6.12,
      "grad_norm": 0.0,
      "learning_rate": 1.3880000000000001e-05,
      "loss": 0.0,
      "step": 76500
    },
    {
      "epoch": 6.16,
      "grad_norm": 0.0,
      "learning_rate": 1.384e-05,
      "loss": 0.0,
      "step": 77000
    },
    {
      "epoch": 6.2,
      "grad_norm": 0.0,
      "learning_rate": 1.38e-05,
      "loss": 0.0,
      "step": 77500
    },
    {
      "epoch": 6.24,
      "grad_norm": 0.0,
      "learning_rate": 1.376e-05,
      "loss": 0.0,
      "step": 78000
    },
    {
      "epoch": 6.28,
      "grad_norm": 0.0,
      "learning_rate": 1.3720000000000002e-05,
      "loss": 0.0,
      "step": 78500
    },
    {
      "epoch": 6.32,
      "grad_norm": 0.0,
      "learning_rate": 1.3680000000000003e-05,
      "loss": 0.0,
      "step": 79000
    },
    {
      "epoch": 6.36,
      "grad_norm": 0.0,
      "learning_rate": 1.3640000000000002e-05,
      "loss": 0.0,
      "step": 79500
    },
    {
      "epoch": 6.4,
      "grad_norm": 0.0,
      "learning_rate": 1.3600000000000002e-05,
      "loss": 0.0,
      "step": 80000
    },
    {
      "epoch": 6.44,
      "grad_norm": 0.0,
      "learning_rate": 1.3560000000000002e-05,
      "loss": 0.0,
      "step": 80500
    },
    {
      "epoch": 6.48,
      "grad_norm": 0.0,
      "learning_rate": 1.3520000000000003e-05,
      "loss": 0.0,
      "step": 81000
    },
    {
      "epoch": 6.52,
      "grad_norm": 0.0,
      "learning_rate": 1.3480000000000001e-05,
      "loss": 0.0,
      "step": 81500
    },
    {
      "epoch": 6.5600000000000005,
      "grad_norm": 0.0,
      "learning_rate": 1.3440000000000002e-05,
      "loss": 0.0,
      "step": 82000
    },
    {
      "epoch": 6.6,
      "grad_norm": 0.0,
      "learning_rate": 1.3400000000000002e-05,
      "loss": 0.0,
      "step": 82500
    },
    {
      "epoch": 6.64,
      "grad_norm": 0.0,
      "learning_rate": 1.3360000000000003e-05,
      "loss": 0.0,
      "step": 83000
    },
    {
      "epoch": 6.68,
      "grad_norm": 0.0,
      "learning_rate": 1.3320000000000001e-05,
      "loss": 0.0,
      "step": 83500
    },
    {
      "epoch": 6.72,
      "grad_norm": 0.0,
      "learning_rate": 1.3280000000000002e-05,
      "loss": 0.0,
      "step": 84000
    },
    {
      "epoch": 6.76,
      "grad_norm": 0.0,
      "learning_rate": 1.3240000000000002e-05,
      "loss": 0.0,
      "step": 84500
    },
    {
      "epoch": 6.8,
      "grad_norm": 0.0,
      "learning_rate": 1.3200000000000002e-05,
      "loss": 0.0,
      "step": 85000
    },
    {
      "epoch": 6.84,
      "grad_norm": 0.0,
      "learning_rate": 1.3160000000000001e-05,
      "loss": 0.0,
      "step": 85500
    },
    {
      "epoch": 6.88,
      "grad_norm": 0.0,
      "learning_rate": 1.3120000000000001e-05,
      "loss": 0.0,
      "step": 86000
    },
    {
      "epoch": 6.92,
      "grad_norm": 0.0,
      "learning_rate": 1.3080000000000002e-05,
      "loss": 0.0,
      "step": 86500
    },
    {
      "epoch": 6.96,
      "grad_norm": 0.0,
      "learning_rate": 1.3040000000000002e-05,
      "loss": 0.0,
      "step": 87000
    },
    {
      "epoch": 7.0,
      "grad_norm": 0.0,
      "learning_rate": 1.3000000000000001e-05,
      "loss": 0.0,
      "step": 87500
    },
    {
      "epoch": 7.04,
      "grad_norm": 0.0,
      "learning_rate": 1.2960000000000001e-05,
      "loss": 0.0,
      "step": 88000
    },
    {
      "epoch": 7.08,
      "grad_norm": 0.0,
      "learning_rate": 1.2920000000000002e-05,
      "loss": 0.0,
      "step": 88500
    },
    {
      "epoch": 7.12,
      "grad_norm": 0.0,
      "learning_rate": 1.2880000000000002e-05,
      "loss": 0.0,
      "step": 89000
    },
    {
      "epoch": 7.16,
      "grad_norm": 0.0,
      "learning_rate": 1.284e-05,
      "loss": 0.0,
      "step": 89500
    },
    {
      "epoch": 7.2,
      "grad_norm": 0.0,
      "learning_rate": 1.2800000000000001e-05,
      "loss": 0.0,
      "step": 90000
    },
    {
      "epoch": 7.24,
      "grad_norm": 0.0,
      "learning_rate": 1.2760000000000001e-05,
      "loss": 0.0,
      "step": 90500
    },
    {
      "epoch": 7.28,
      "grad_norm": 0.0,
      "learning_rate": 1.2720000000000002e-05,
      "loss": 0.0,
      "step": 91000
    },
    {
      "epoch": 7.32,
      "grad_norm": 0.0,
      "learning_rate": 1.268e-05,
      "loss": 0.0,
      "step": 91500
    },
    {
      "epoch": 7.36,
      "grad_norm": 0.0,
      "learning_rate": 1.2640000000000001e-05,
      "loss": 0.0,
      "step": 92000
    },
    {
      "epoch": 7.4,
      "grad_norm": 0.0,
      "learning_rate": 1.2600000000000001e-05,
      "loss": 0.0,
      "step": 92500
    },
    {
      "epoch": 7.44,
      "grad_norm": 0.0,
      "learning_rate": 1.2560000000000002e-05,
      "loss": 0.0,
      "step": 93000
    },
    {
      "epoch": 7.48,
      "grad_norm": 0.0,
      "learning_rate": 1.252e-05,
      "loss": 0.0,
      "step": 93500
    },
    {
      "epoch": 7.52,
      "grad_norm": 0.0,
      "learning_rate": 1.248e-05,
      "loss": 0.0,
      "step": 94000
    },
    {
      "epoch": 7.5600000000000005,
      "grad_norm": 0.0,
      "learning_rate": 1.2440000000000001e-05,
      "loss": 0.0,
      "step": 94500
    },
    {
      "epoch": 7.6,
      "grad_norm": 0.0,
      "learning_rate": 1.2400000000000002e-05,
      "loss": 0.0,
      "step": 95000
    },
    {
      "epoch": 7.64,
      "grad_norm": 0.0,
      "learning_rate": 1.236e-05,
      "loss": 0.0,
      "step": 95500
    },
    {
      "epoch": 7.68,
      "grad_norm": 0.0,
      "learning_rate": 1.232e-05,
      "loss": 0.0,
      "step": 96000
    },
    {
      "epoch": 7.72,
      "grad_norm": 0.0,
      "learning_rate": 1.2280000000000001e-05,
      "loss": 0.0,
      "step": 96500
    },
    {
      "epoch": 7.76,
      "grad_norm": 0.0,
      "learning_rate": 1.2240000000000001e-05,
      "loss": 0.0,
      "step": 97000
    },
    {
      "epoch": 7.8,
      "grad_norm": 0.0,
      "learning_rate": 1.22e-05,
      "loss": 0.0,
      "step": 97500
    },
    {
      "epoch": 7.84,
      "grad_norm": 0.0,
      "learning_rate": 1.216e-05,
      "loss": 0.0,
      "step": 98000
    },
    {
      "epoch": 7.88,
      "grad_norm": 0.0,
      "learning_rate": 1.2120000000000001e-05,
      "loss": 0.0,
      "step": 98500
    },
    {
      "epoch": 7.92,
      "grad_norm": 0.0,
      "learning_rate": 1.2080000000000001e-05,
      "loss": 0.0,
      "step": 99000
    },
    {
      "epoch": 7.96,
      "grad_norm": 0.0,
      "learning_rate": 1.204e-05,
      "loss": 0.0,
      "step": 99500
    },
    {
      "epoch": 8.0,
      "grad_norm": 0.0,
      "learning_rate": 1.2e-05,
      "loss": 0.0,
      "step": 100000
    },
    {
      "epoch": 8.04,
      "grad_norm": 0.0,
      "learning_rate": 1.196e-05,
      "loss": 0.0,
      "step": 100500
    },
    {
      "epoch": 8.08,
      "grad_norm": 0.0,
      "learning_rate": 1.1920000000000001e-05,
      "loss": 0.0,
      "step": 101000
    },
    {
      "epoch": 8.12,
      "grad_norm": 0.0,
      "learning_rate": 1.188e-05,
      "loss": 0.0,
      "step": 101500
    },
    {
      "epoch": 8.16,
      "grad_norm": 0.0,
      "learning_rate": 1.184e-05,
      "loss": 0.0,
      "step": 102000
    },
    {
      "epoch": 8.2,
      "grad_norm": 0.0,
      "learning_rate": 1.18e-05,
      "loss": 0.0,
      "step": 102500
    },
    {
      "epoch": 8.24,
      "grad_norm": 0.0,
      "learning_rate": 1.1760000000000001e-05,
      "loss": 0.0,
      "step": 103000
    },
    {
      "epoch": 8.28,
      "grad_norm": 0.0,
      "learning_rate": 1.172e-05,
      "loss": 0.0,
      "step": 103500
    },
    {
      "epoch": 8.32,
      "grad_norm": 0.0,
      "learning_rate": 1.168e-05,
      "loss": 0.0,
      "step": 104000
    },
    {
      "epoch": 8.36,
      "grad_norm": 0.0,
      "learning_rate": 1.164e-05,
      "loss": 0.0,
      "step": 104500
    },
    {
      "epoch": 8.4,
      "grad_norm": 0.0,
      "learning_rate": 1.16e-05,
      "loss": 0.0,
      "step": 105000
    },
    {
      "epoch": 8.44,
      "grad_norm": 0.0,
      "learning_rate": 1.156e-05,
      "loss": 0.0,
      "step": 105500
    },
    {
      "epoch": 8.48,
      "grad_norm": 0.0,
      "learning_rate": 1.152e-05,
      "loss": 0.0,
      "step": 106000
    },
    {
      "epoch": 8.52,
      "grad_norm": 0.0,
      "learning_rate": 1.148e-05,
      "loss": 0.0,
      "step": 106500
    },
    {
      "epoch": 8.56,
      "grad_norm": 0.0,
      "learning_rate": 1.144e-05,
      "loss": 0.0,
      "step": 107000
    },
    {
      "epoch": 8.6,
      "grad_norm": 0.0,
      "learning_rate": 1.14e-05,
      "loss": 0.0,
      "step": 107500
    },
    {
      "epoch": 8.64,
      "grad_norm": 0.0,
      "learning_rate": 1.136e-05,
      "loss": 0.0,
      "step": 108000
    },
    {
      "epoch": 8.68,
      "grad_norm": 0.0,
      "learning_rate": 1.132e-05,
      "loss": 0.0,
      "step": 108500
    },
    {
      "epoch": 8.72,
      "grad_norm": 0.0,
      "learning_rate": 1.128e-05,
      "loss": 0.0,
      "step": 109000
    },
    {
      "epoch": 8.76,
      "grad_norm": 0.0,
      "learning_rate": 1.1240000000000002e-05,
      "loss": 0.0,
      "step": 109500
    },
    {
      "epoch": 8.8,
      "grad_norm": 0.0,
      "learning_rate": 1.1200000000000001e-05,
      "loss": 0.0,
      "step": 110000
    },
    {
      "epoch": 8.84,
      "grad_norm": 0.0,
      "learning_rate": 1.1160000000000002e-05,
      "loss": 0.0,
      "step": 110500
    },
    {
      "epoch": 8.88,
      "grad_norm": 0.0,
      "learning_rate": 1.1120000000000002e-05,
      "loss": 0.0,
      "step": 111000
    },
    {
      "epoch": 8.92,
      "grad_norm": 0.0,
      "learning_rate": 1.1080000000000002e-05,
      "loss": 0.0,
      "step": 111500
    },
    {
      "epoch": 8.96,
      "grad_norm": 0.0,
      "learning_rate": 1.1040000000000001e-05,
      "loss": 0.0,
      "step": 112000
    },
    {
      "epoch": 9.0,
      "grad_norm": 0.0,
      "learning_rate": 1.1000000000000001e-05,
      "loss": 0.0,
      "step": 112500
    },
    {
      "epoch": 9.04,
      "grad_norm": 0.0,
      "learning_rate": 1.0960000000000002e-05,
      "loss": 0.0,
      "step": 113000
    },
    {
      "epoch": 9.08,
      "grad_norm": 0.0,
      "learning_rate": 1.0920000000000002e-05,
      "loss": 0.0,
      "step": 113500
    },
    {
      "epoch": 9.12,
      "grad_norm": 0.0,
      "learning_rate": 1.0880000000000001e-05,
      "loss": 0.0,
      "step": 114000
    },
    {
      "epoch": 9.16,
      "grad_norm": 0.0,
      "learning_rate": 1.0840000000000001e-05,
      "loss": 0.0,
      "step": 114500
    },
    {
      "epoch": 9.2,
      "grad_norm": 0.0,
      "learning_rate": 1.0800000000000002e-05,
      "loss": 0.0,
      "step": 115000
    },
    {
      "epoch": 9.24,
      "grad_norm": 0.0,
      "learning_rate": 1.0760000000000002e-05,
      "loss": 0.0,
      "step": 115500
    },
    {
      "epoch": 9.28,
      "grad_norm": 0.0,
      "learning_rate": 1.072e-05,
      "loss": 0.0,
      "step": 116000
    },
    {
      "epoch": 9.32,
      "grad_norm": 0.0,
      "learning_rate": 1.0680000000000001e-05,
      "loss": 0.0,
      "step": 116500
    },
    {
      "epoch": 9.36,
      "grad_norm": 0.0,
      "learning_rate": 1.0640000000000001e-05,
      "loss": 0.0,
      "step": 117000
    },
    {
      "epoch": 9.4,
      "grad_norm": 0.0,
      "learning_rate": 1.0600000000000002e-05,
      "loss": 0.0,
      "step": 117500
    },
    {
      "epoch": 9.44,
      "grad_norm": 0.0,
      "learning_rate": 1.056e-05,
      "loss": 0.0,
      "step": 118000
    },
    {
      "epoch": 9.48,
      "grad_norm": 0.0,
      "learning_rate": 1.0520000000000001e-05,
      "loss": 0.0,
      "step": 118500
    },
    {
      "epoch": 9.52,
      "grad_norm": 0.0,
      "learning_rate": 1.0480000000000001e-05,
      "loss": 0.0,
      "step": 119000
    },
    {
      "epoch": 9.56,
      "grad_norm": 0.0,
      "learning_rate": 1.0440000000000002e-05,
      "loss": 0.0,
      "step": 119500
    },
    {
      "epoch": 9.6,
      "grad_norm": 0.0,
      "learning_rate": 1.04e-05,
      "loss": 0.0,
      "step": 120000
    },
    {
      "epoch": 9.64,
      "grad_norm": 0.0,
      "learning_rate": 1.036e-05,
      "loss": 0.0,
      "step": 120500
    },
    {
      "epoch": 9.68,
      "grad_norm": 0.0,
      "learning_rate": 1.0320000000000001e-05,
      "loss": 0.0,
      "step": 121000
    },
    {
      "epoch": 9.72,
      "grad_norm": 0.0,
      "learning_rate": 1.0280000000000002e-05,
      "loss": 0.0,
      "step": 121500
    },
    {
      "epoch": 9.76,
      "grad_norm": 0.0,
      "learning_rate": 1.024e-05,
      "loss": 0.0,
      "step": 122000
    },
    {
      "epoch": 9.8,
      "grad_norm": 0.0,
      "learning_rate": 1.02e-05,
      "loss": 0.0,
      "step": 122500
    },
    {
      "epoch": 9.84,
      "grad_norm": 0.0,
      "learning_rate": 1.0160000000000001e-05,
      "loss": 0.0,
      "step": 123000
    },
    {
      "epoch": 9.88,
      "grad_norm": 0.0,
      "learning_rate": 1.0120000000000001e-05,
      "loss": 0.0,
      "step": 123500
    },
    {
      "epoch": 9.92,
      "grad_norm": 0.0,
      "learning_rate": 1.008e-05,
      "loss": 0.0,
      "step": 124000
    },
    {
      "epoch": 9.96,
      "grad_norm": 0.0,
      "learning_rate": 1.004e-05,
      "loss": 0.0,
      "step": 124500
    },
    {
      "epoch": 10.0,
      "grad_norm": 0.0,
      "learning_rate": 1e-05,
      "loss": 0.0,
      "step": 125000
    },
    {
      "epoch": 10.04,
      "grad_norm": 0.0,
      "learning_rate": 9.960000000000001e-06,
      "loss": 0.0,
      "step": 125500
    },
    {
      "epoch": 10.08,
      "grad_norm": 0.0,
      "learning_rate": 9.920000000000002e-06,
      "loss": 0.0,
      "step": 126000
    },
    {
      "epoch": 10.12,
      "grad_norm": 0.0,
      "learning_rate": 9.88e-06,
      "loss": 0.0,
      "step": 126500
    },
    {
      "epoch": 10.16,
      "grad_norm": 0.0,
      "learning_rate": 9.84e-06,
      "loss": 0.0,
      "step": 127000
    },
    {
      "epoch": 10.2,
      "grad_norm": 0.0,
      "learning_rate": 9.800000000000001e-06,
      "loss": 0.0,
      "step": 127500
    },
    {
      "epoch": 10.24,
      "grad_norm": 0.0,
      "learning_rate": 9.760000000000001e-06,
      "loss": 0.0,
      "step": 128000
    },
    {
      "epoch": 10.28,
      "grad_norm": 0.0,
      "learning_rate": 9.72e-06,
      "loss": 0.0,
      "step": 128500
    },
    {
      "epoch": 10.32,
      "grad_norm": 0.0,
      "learning_rate": 9.68e-06,
      "loss": 0.0,
      "step": 129000
    },
    {
      "epoch": 10.36,
      "grad_norm": 0.0,
      "learning_rate": 9.640000000000001e-06,
      "loss": 0.0,
      "step": 129500
    },
    {
      "epoch": 10.4,
      "grad_norm": 0.0,
      "learning_rate": 9.600000000000001e-06,
      "loss": 0.0,
      "step": 130000
    },
    {
      "epoch": 10.44,
      "grad_norm": 0.0,
      "learning_rate": 9.56e-06,
      "loss": 0.0,
      "step": 130500
    },
    {
      "epoch": 10.48,
      "grad_norm": 0.0,
      "learning_rate": 9.52e-06,
      "loss": 0.0,
      "step": 131000
    },
    {
      "epoch": 10.52,
      "grad_norm": 0.0,
      "learning_rate": 9.48e-06,
      "loss": 0.0,
      "step": 131500
    },
    {
      "epoch": 10.56,
      "grad_norm": 0.0,
      "learning_rate": 9.440000000000001e-06,
      "loss": 0.0,
      "step": 132000
    },
    {
      "epoch": 10.6,
      "grad_norm": 0.0,
      "learning_rate": 9.4e-06,
      "loss": 0.0,
      "step": 132500
    },
    {
      "epoch": 10.64,
      "grad_norm": 0.0,
      "learning_rate": 9.360000000000002e-06,
      "loss": 0.0,
      "step": 133000
    },
    {
      "epoch": 10.68,
      "grad_norm": 0.0,
      "learning_rate": 9.32e-06,
      "loss": 0.0,
      "step": 133500
    },
    {
      "epoch": 10.72,
      "grad_norm": 0.0,
      "learning_rate": 9.280000000000001e-06,
      "loss": 0.0,
      "step": 134000
    },
    {
      "epoch": 10.76,
      "grad_norm": 0.0,
      "learning_rate": 9.240000000000001e-06,
      "loss": 0.0,
      "step": 134500
    },
    {
      "epoch": 10.8,
      "grad_norm": 0.0,
      "learning_rate": 9.200000000000002e-06,
      "loss": 0.0,
      "step": 135000
    },
    {
      "epoch": 10.84,
      "grad_norm": 0.0,
      "learning_rate": 9.16e-06,
      "loss": 0.0,
      "step": 135500
    },
    {
      "epoch": 10.88,
      "grad_norm": 0.0,
      "learning_rate": 9.12e-06,
      "loss": 0.0,
      "step": 136000
    },
    {
      "epoch": 10.92,
      "grad_norm": 0.0,
      "learning_rate": 9.080000000000001e-06,
      "loss": 0.0,
      "step": 136500
    },
    {
      "epoch": 10.96,
      "grad_norm": 0.0,
      "learning_rate": 9.040000000000002e-06,
      "loss": 0.0,
      "step": 137000
    },
    {
      "epoch": 11.0,
      "grad_norm": 0.0,
      "learning_rate": 9e-06,
      "loss": 0.0,
      "step": 137500
    },
    {
      "epoch": 11.04,
      "grad_norm": 0.0,
      "learning_rate": 8.96e-06,
      "loss": 0.0,
      "step": 138000
    },
    {
      "epoch": 11.08,
      "grad_norm": 0.0,
      "learning_rate": 8.920000000000001e-06,
      "loss": 0.0,
      "step": 138500
    },
    {
      "epoch": 11.12,
      "grad_norm": 0.0,
      "learning_rate": 8.880000000000001e-06,
      "loss": 0.0,
      "step": 139000
    },
    {
      "epoch": 11.16,
      "grad_norm": 0.0,
      "learning_rate": 8.84e-06,
      "loss": 0.0,
      "step": 139500
    },
    {
      "epoch": 11.2,
      "grad_norm": 0.0,
      "learning_rate": 8.8e-06,
      "loss": 0.0,
      "step": 140000
    },
    {
      "epoch": 11.24,
      "grad_norm": 0.0,
      "learning_rate": 8.76e-06,
      "loss": 0.0,
      "step": 140500
    },
    {
      "epoch": 11.28,
      "grad_norm": 0.0,
      "learning_rate": 8.720000000000001e-06,
      "loss": 0.0,
      "step": 141000
    },
    {
      "epoch": 11.32,
      "grad_norm": 0.0,
      "learning_rate": 8.68e-06,
      "loss": 0.0,
      "step": 141500
    },
    {
      "epoch": 11.36,
      "grad_norm": 0.0,
      "learning_rate": 8.64e-06,
      "loss": 0.0,
      "step": 142000
    },
    {
      "epoch": 11.4,
      "grad_norm": 0.0,
      "learning_rate": 8.6e-06,
      "loss": 0.0,
      "step": 142500
    },
    {
      "epoch": 11.44,
      "grad_norm": 0.0,
      "learning_rate": 8.560000000000001e-06,
      "loss": 0.0,
      "step": 143000
    },
    {
      "epoch": 11.48,
      "grad_norm": 0.0,
      "learning_rate": 8.52e-06,
      "loss": 0.0,
      "step": 143500
    },
    {
      "epoch": 11.52,
      "grad_norm": 0.0,
      "learning_rate": 8.48e-06,
      "loss": 0.0,
      "step": 144000
    },
    {
      "epoch": 11.56,
      "grad_norm": 0.0,
      "learning_rate": 8.44e-06,
      "loss": 0.0,
      "step": 144500
    },
    {
      "epoch": 11.6,
      "grad_norm": 0.0,
      "learning_rate": 8.400000000000001e-06,
      "loss": 0.0,
      "step": 145000
    },
    {
      "epoch": 11.64,
      "grad_norm": 0.0,
      "learning_rate": 8.36e-06,
      "loss": 0.0,
      "step": 145500
    },
    {
      "epoch": 11.68,
      "grad_norm": 0.0,
      "learning_rate": 8.32e-06,
      "loss": 0.0,
      "step": 146000
    },
    {
      "epoch": 11.72,
      "grad_norm": 0.0,
      "learning_rate": 8.28e-06,
      "loss": 0.0,
      "step": 146500
    },
    {
      "epoch": 11.76,
      "grad_norm": 0.0,
      "learning_rate": 8.24e-06,
      "loss": 0.0,
      "step": 147000
    },
    {
      "epoch": 11.8,
      "grad_norm": 0.0,
      "learning_rate": 8.2e-06,
      "loss": 0.0,
      "step": 147500
    },
    {
      "epoch": 11.84,
      "grad_norm": 0.0,
      "learning_rate": 8.16e-06,
      "loss": 0.0,
      "step": 148000
    },
    {
      "epoch": 11.88,
      "grad_norm": 0.0,
      "learning_rate": 8.120000000000002e-06,
      "loss": 0.0,
      "step": 148500
    },
    {
      "epoch": 11.92,
      "grad_norm": 0.0,
      "learning_rate": 8.08e-06,
      "loss": 0.0,
      "step": 149000
    },
    {
      "epoch": 11.96,
      "grad_norm": 0.0,
      "learning_rate": 8.040000000000001e-06,
      "loss": 0.0,
      "step": 149500
    },
    {
      "epoch": 12.0,
      "grad_norm": 0.0,
      "learning_rate": 8.000000000000001e-06,
      "loss": 0.0,
      "step": 150000
    },
    {
      "epoch": 12.04,
      "grad_norm": 0.0,
      "learning_rate": 7.960000000000002e-06,
      "loss": 0.0,
      "step": 150500
    },
    {
      "epoch": 12.08,
      "grad_norm": 0.0,
      "learning_rate": 7.92e-06,
      "loss": 0.0,
      "step": 151000
    },
    {
      "epoch": 12.12,
      "grad_norm": 0.0,
      "learning_rate": 7.88e-06,
      "loss": 0.0,
      "step": 151500
    },
    {
      "epoch": 12.16,
      "grad_norm": 0.0,
      "learning_rate": 7.840000000000001e-06,
      "loss": 0.0,
      "step": 152000
    },
    {
      "epoch": 12.2,
      "grad_norm": 0.0,
      "learning_rate": 7.800000000000002e-06,
      "loss": 0.0,
      "step": 152500
    },
    {
      "epoch": 12.24,
      "grad_norm": 0.0,
      "learning_rate": 7.76e-06,
      "loss": 0.0,
      "step": 153000
    },
    {
      "epoch": 12.28,
      "grad_norm": 0.0,
      "learning_rate": 7.72e-06,
      "loss": 0.0,
      "step": 153500
    },
    {
      "epoch": 12.32,
      "grad_norm": 0.0,
      "learning_rate": 7.680000000000001e-06,
      "loss": 0.0,
      "step": 154000
    },
    {
      "epoch": 12.36,
      "grad_norm": 0.0,
      "learning_rate": 7.640000000000001e-06,
      "loss": 0.0,
      "step": 154500
    },
    {
      "epoch": 12.4,
      "grad_norm": 0.0,
      "learning_rate": 7.600000000000001e-06,
      "loss": 0.0,
      "step": 155000
    },
    {
      "epoch": 12.44,
      "grad_norm": 0.0,
      "learning_rate": 7.5600000000000005e-06,
      "loss": 0.0,
      "step": 155500
    },
    {
      "epoch": 12.48,
      "grad_norm": 0.0,
      "learning_rate": 7.520000000000001e-06,
      "loss": 0.0,
      "step": 156000
    },
    {
      "epoch": 12.52,
      "grad_norm": 0.0,
      "learning_rate": 7.48e-06,
      "loss": 0.0,
      "step": 156500
    },
    {
      "epoch": 12.56,
      "grad_norm": 0.0,
      "learning_rate": 7.440000000000001e-06,
      "loss": 0.0,
      "step": 157000
    },
    {
      "epoch": 12.6,
      "grad_norm": 0.0,
      "learning_rate": 7.4e-06,
      "loss": 0.0,
      "step": 157500
    },
    {
      "epoch": 12.64,
      "grad_norm": 0.0,
      "learning_rate": 7.360000000000001e-06,
      "loss": 0.0,
      "step": 158000
    },
    {
      "epoch": 12.68,
      "grad_norm": 0.0,
      "learning_rate": 7.32e-06,
      "loss": 0.0,
      "step": 158500
    },
    {
      "epoch": 12.72,
      "grad_norm": 0.0,
      "learning_rate": 7.280000000000001e-06,
      "loss": 0.0,
      "step": 159000
    },
    {
      "epoch": 12.76,
      "grad_norm": 0.0,
      "learning_rate": 7.24e-06,
      "loss": 0.0,
      "step": 159500
    },
    {
      "epoch": 12.8,
      "grad_norm": 0.0,
      "learning_rate": 7.2000000000000005e-06,
      "loss": 0.0,
      "step": 160000
    },
    {
      "epoch": 12.84,
      "grad_norm": 0.0,
      "learning_rate": 7.16e-06,
      "loss": 0.0,
      "step": 160500
    },
    {
      "epoch": 12.88,
      "grad_norm": 0.0,
      "learning_rate": 7.1200000000000004e-06,
      "loss": 0.0,
      "step": 161000
    },
    {
      "epoch": 12.92,
      "grad_norm": 0.0,
      "learning_rate": 7.08e-06,
      "loss": 0.0,
      "step": 161500
    },
    {
      "epoch": 12.96,
      "grad_norm": 0.0,
      "learning_rate": 7.04e-06,
      "loss": 0.0,
      "step": 162000
    },
    {
      "epoch": 13.0,
      "grad_norm": 0.0,
      "learning_rate": 7e-06,
      "loss": 0.0,
      "step": 162500
    },
    {
      "epoch": 13.04,
      "grad_norm": 0.0,
      "learning_rate": 6.96e-06,
      "loss": 0.0,
      "step": 163000
    },
    {
      "epoch": 13.08,
      "grad_norm": 0.0,
      "learning_rate": 6.92e-06,
      "loss": 0.0,
      "step": 163500
    },
    {
      "epoch": 13.12,
      "grad_norm": 0.0,
      "learning_rate": 6.88e-06,
      "loss": 0.0,
      "step": 164000
    },
    {
      "epoch": 13.16,
      "grad_norm": 0.0,
      "learning_rate": 6.8400000000000014e-06,
      "loss": 0.0,
      "step": 164500
    },
    {
      "epoch": 13.2,
      "grad_norm": 0.0,
      "learning_rate": 6.800000000000001e-06,
      "loss": 0.0,
      "step": 165000
    },
    {
      "epoch": 13.24,
      "grad_norm": 0.0,
      "learning_rate": 6.760000000000001e-06,
      "loss": 0.0,
      "step": 165500
    },
    {
      "epoch": 13.28,
      "grad_norm": 0.0,
      "learning_rate": 6.720000000000001e-06,
      "loss": 0.0,
      "step": 166000
    },
    {
      "epoch": 13.32,
      "grad_norm": 0.0,
      "learning_rate": 6.680000000000001e-06,
      "loss": 0.0,
      "step": 166500
    },
    {
      "epoch": 13.36,
      "grad_norm": 0.0,
      "learning_rate": 6.640000000000001e-06,
      "loss": 0.0,
      "step": 167000
    },
    {
      "epoch": 13.4,
      "grad_norm": 0.0,
      "learning_rate": 6.600000000000001e-06,
      "loss": 0.0,
      "step": 167500
    },
    {
      "epoch": 13.44,
      "grad_norm": 0.0,
      "learning_rate": 6.560000000000001e-06,
      "loss": 0.0,
      "step": 168000
    },
    {
      "epoch": 13.48,
      "grad_norm": 0.0,
      "learning_rate": 6.520000000000001e-06,
      "loss": 0.0,
      "step": 168500
    },
    {
      "epoch": 13.52,
      "grad_norm": 0.0,
      "learning_rate": 6.480000000000001e-06,
      "loss": 0.0,
      "step": 169000
    },
    {
      "epoch": 13.56,
      "grad_norm": 0.0,
      "learning_rate": 6.440000000000001e-06,
      "loss": 0.0,
      "step": 169500
    },
    {
      "epoch": 13.6,
      "grad_norm": 0.0,
      "learning_rate": 6.4000000000000006e-06,
      "loss": 0.0,
      "step": 170000
    },
    {
      "epoch": 13.64,
      "grad_norm": 0.0,
      "learning_rate": 6.360000000000001e-06,
      "loss": 0.0,
      "step": 170500
    },
    {
      "epoch": 13.68,
      "grad_norm": 0.0,
      "learning_rate": 6.3200000000000005e-06,
      "loss": 0.0,
      "step": 171000
    },
    {
      "epoch": 13.72,
      "grad_norm": 0.0,
      "learning_rate": 6.280000000000001e-06,
      "loss": 0.0,
      "step": 171500
    },
    {
      "epoch": 13.76,
      "grad_norm": 0.0,
      "learning_rate": 6.24e-06,
      "loss": 0.0,
      "step": 172000
    },
    {
      "epoch": 13.8,
      "grad_norm": 0.0,
      "learning_rate": 6.200000000000001e-06,
      "loss": 0.0,
      "step": 172500
    },
    {
      "epoch": 13.84,
      "grad_norm": 0.0,
      "learning_rate": 6.16e-06,
      "loss": 0.0,
      "step": 173000
    },
    {
      "epoch": 13.88,
      "grad_norm": 0.0,
      "learning_rate": 6.120000000000001e-06,
      "loss": 0.0,
      "step": 173500
    },
    {
      "epoch": 13.92,
      "grad_norm": 0.0,
      "learning_rate": 6.08e-06,
      "loss": 0.0,
      "step": 174000
    },
    {
      "epoch": 13.96,
      "grad_norm": 0.0,
      "learning_rate": 6.040000000000001e-06,
      "loss": 0.0,
      "step": 174500
    },
    {
      "epoch": 14.0,
      "grad_norm": 0.0,
      "learning_rate": 6e-06,
      "loss": 0.0,
      "step": 175000
    },
    {
      "epoch": 14.04,
      "grad_norm": 0.0,
      "learning_rate": 5.9600000000000005e-06,
      "loss": 0.0,
      "step": 175500
    },
    {
      "epoch": 14.08,
      "grad_norm": 0.0,
      "learning_rate": 5.92e-06,
      "loss": 0.0,
      "step": 176000
    },
    {
      "epoch": 14.12,
      "grad_norm": 0.0,
      "learning_rate": 5.8800000000000005e-06,
      "loss": 0.0,
      "step": 176500
    },
    {
      "epoch": 14.16,
      "grad_norm": 0.0,
      "learning_rate": 5.84e-06,
      "loss": 0.0,
      "step": 177000
    },
    {
      "epoch": 14.2,
      "grad_norm": 0.0,
      "learning_rate": 5.8e-06,
      "loss": 0.0,
      "step": 177500
    },
    {
      "epoch": 14.24,
      "grad_norm": 0.0,
      "learning_rate": 5.76e-06,
      "loss": 0.0,
      "step": 178000
    },
    {
      "epoch": 14.28,
      "grad_norm": 0.0,
      "learning_rate": 5.72e-06,
      "loss": 0.0,
      "step": 178500
    },
    {
      "epoch": 14.32,
      "grad_norm": 0.0,
      "learning_rate": 5.68e-06,
      "loss": 0.0,
      "step": 179000
    },
    {
      "epoch": 14.36,
      "grad_norm": 0.0,
      "learning_rate": 5.64e-06,
      "loss": 0.0,
      "step": 179500
    },
    {
      "epoch": 14.4,
      "grad_norm": 0.0,
      "learning_rate": 5.600000000000001e-06,
      "loss": 0.0,
      "step": 180000
    },
    {
      "epoch": 14.44,
      "grad_norm": 0.0,
      "learning_rate": 5.560000000000001e-06,
      "loss": 0.0,
      "step": 180500
    },
    {
      "epoch": 14.48,
      "grad_norm": 0.0,
      "learning_rate": 5.5200000000000005e-06,
      "loss": 0.0,
      "step": 181000
    },
    {
      "epoch": 14.52,
      "grad_norm": 0.0,
      "learning_rate": 5.480000000000001e-06,
      "loss": 0.0,
      "step": 181500
    },
    {
      "epoch": 14.56,
      "grad_norm": 0.0,
      "learning_rate": 5.4400000000000004e-06,
      "loss": 0.0,
      "step": 182000
    },
    {
      "epoch": 14.6,
      "grad_norm": 0.0,
      "learning_rate": 5.400000000000001e-06,
      "loss": 0.0,
      "step": 182500
    },
    {
      "epoch": 14.64,
      "grad_norm": 0.0,
      "learning_rate": 5.36e-06,
      "loss": 0.0,
      "step": 183000
    },
    {
      "epoch": 14.68,
      "grad_norm": 0.0,
      "learning_rate": 5.320000000000001e-06,
      "loss": 0.0,
      "step": 183500
    },
    {
      "epoch": 14.72,
      "grad_norm": 0.0,
      "learning_rate": 5.28e-06,
      "loss": 0.0,
      "step": 184000
    },
    {
      "epoch": 14.76,
      "grad_norm": 0.0,
      "learning_rate": 5.240000000000001e-06,
      "loss": 0.0,
      "step": 184500
    },
    {
      "epoch": 14.8,
      "grad_norm": 0.0,
      "learning_rate": 5.2e-06,
      "loss": 0.0,
      "step": 185000
    },
    {
      "epoch": 14.84,
      "grad_norm": 0.0,
      "learning_rate": 5.1600000000000006e-06,
      "loss": 0.0,
      "step": 185500
    },
    {
      "epoch": 14.88,
      "grad_norm": 0.0,
      "learning_rate": 5.12e-06,
      "loss": 0.0,
      "step": 186000
    },
    {
      "epoch": 14.92,
      "grad_norm": 0.0,
      "learning_rate": 5.0800000000000005e-06,
      "loss": 0.0,
      "step": 186500
    },
    {
      "epoch": 14.96,
      "grad_norm": 0.0,
      "learning_rate": 5.04e-06,
      "loss": 0.0,
      "step": 187000
    },
    {
      "epoch": 15.0,
      "grad_norm": 0.0,
      "learning_rate": 5e-06,
      "loss": 0.0,
      "step": 187500
    },
    {
      "epoch": 15.04,
      "grad_norm": 0.0,
      "learning_rate": 4.960000000000001e-06,
      "loss": 0.0,
      "step": 188000
    },
    {
      "epoch": 15.08,
      "grad_norm": 0.0,
      "learning_rate": 4.92e-06,
      "loss": 0.0,
      "step": 188500
    },
    {
      "epoch": 15.12,
      "grad_norm": 0.0,
      "learning_rate": 4.880000000000001e-06,
      "loss": 0.0,
      "step": 189000
    },
    {
      "epoch": 15.16,
      "grad_norm": 0.0,
      "learning_rate": 4.84e-06,
      "loss": 0.0,
      "step": 189500
    },
    {
      "epoch": 15.2,
      "grad_norm": 0.0,
      "learning_rate": 4.800000000000001e-06,
      "loss": 0.0,
      "step": 190000
    },
    {
      "epoch": 15.24,
      "grad_norm": 0.0,
      "learning_rate": 4.76e-06,
      "loss": 0.0,
      "step": 190500
    },
    {
      "epoch": 15.28,
      "grad_norm": 0.0,
      "learning_rate": 4.7200000000000005e-06,
      "loss": 0.0,
      "step": 191000
    },
    {
      "epoch": 15.32,
      "grad_norm": 0.0,
      "learning_rate": 4.680000000000001e-06,
      "loss": 0.0,
      "step": 191500
    },
    {
      "epoch": 15.36,
      "grad_norm": 0.0,
      "learning_rate": 4.6400000000000005e-06,
      "loss": 0.0,
      "step": 192000
    },
    {
      "epoch": 15.4,
      "grad_norm": 0.0,
      "learning_rate": 4.600000000000001e-06,
      "loss": 0.0,
      "step": 192500
    },
    {
      "epoch": 15.44,
      "grad_norm": 0.0,
      "learning_rate": 4.56e-06,
      "loss": 0.0,
      "step": 193000
    },
    {
      "epoch": 15.48,
      "grad_norm": 0.0,
      "learning_rate": 4.520000000000001e-06,
      "loss": 0.0,
      "step": 193500
    },
    {
      "epoch": 15.52,
      "grad_norm": 0.0,
      "learning_rate": 4.48e-06,
      "loss": 0.0,
      "step": 194000
    },
    {
      "epoch": 15.56,
      "grad_norm": 0.0,
      "learning_rate": 4.440000000000001e-06,
      "loss": 0.0,
      "step": 194500
    },
    {
      "epoch": 15.6,
      "grad_norm": 0.0,
      "learning_rate": 4.4e-06,
      "loss": 0.0,
      "step": 195000
    },
    {
      "epoch": 15.64,
      "grad_norm": 0.0,
      "learning_rate": 4.360000000000001e-06,
      "loss": 0.0,
      "step": 195500
    },
    {
      "epoch": 15.68,
      "grad_norm": 0.0,
      "learning_rate": 4.32e-06,
      "loss": 0.0,
      "step": 196000
    },
    {
      "epoch": 15.72,
      "grad_norm": 0.0,
      "learning_rate": 4.2800000000000005e-06,
      "loss": 0.0,
      "step": 196500
    },
    {
      "epoch": 15.76,
      "grad_norm": 0.0,
      "learning_rate": 4.24e-06,
      "loss": 0.0,
      "step": 197000
    },
    {
      "epoch": 15.8,
      "grad_norm": 0.0,
      "learning_rate": 4.2000000000000004e-06,
      "loss": 0.0,
      "step": 197500
    },
    {
      "epoch": 15.84,
      "grad_norm": 0.0,
      "learning_rate": 4.16e-06,
      "loss": 0.0,
      "step": 198000
    },
    {
      "epoch": 15.88,
      "grad_norm": 0.0,
      "learning_rate": 4.12e-06,
      "loss": 0.0,
      "step": 198500
    },
    {
      "epoch": 15.92,
      "grad_norm": 0.0,
      "learning_rate": 4.08e-06,
      "loss": 0.0,
      "step": 199000
    },
    {
      "epoch": 15.96,
      "grad_norm": 0.0,
      "learning_rate": 4.04e-06,
      "loss": 0.0,
      "step": 199500
    },
    {
      "epoch": 16.0,
      "grad_norm": 0.0,
      "learning_rate": 4.000000000000001e-06,
      "loss": 0.0,
      "step": 200000
    },
    {
      "epoch": 16.04,
      "grad_norm": 0.0,
      "learning_rate": 3.96e-06,
      "loss": 0.0,
      "step": 200500
    },
    {
      "epoch": 16.08,
      "grad_norm": 0.0,
      "learning_rate": 3.920000000000001e-06,
      "loss": 0.0,
      "step": 201000
    },
    {
      "epoch": 16.12,
      "grad_norm": 0.0,
      "learning_rate": 3.88e-06,
      "loss": 0.0,
      "step": 201500
    },
    {
      "epoch": 16.16,
      "grad_norm": 0.0,
      "learning_rate": 3.8400000000000005e-06,
      "loss": 0.0,
      "step": 202000
    },
    {
      "epoch": 16.2,
      "grad_norm": 0.0,
      "learning_rate": 3.8000000000000005e-06,
      "loss": 0.0,
      "step": 202500
    },
    {
      "epoch": 16.24,
      "grad_norm": 0.0,
      "learning_rate": 3.7600000000000004e-06,
      "loss": 0.0,
      "step": 203000
    },
    {
      "epoch": 16.28,
      "grad_norm": 0.0,
      "learning_rate": 3.7200000000000004e-06,
      "loss": 0.0,
      "step": 203500
    },
    {
      "epoch": 16.32,
      "grad_norm": 0.0,
      "learning_rate": 3.6800000000000003e-06,
      "loss": 0.0,
      "step": 204000
    },
    {
      "epoch": 16.36,
      "grad_norm": 0.0,
      "learning_rate": 3.6400000000000003e-06,
      "loss": 0.0,
      "step": 204500
    },
    {
      "epoch": 16.4,
      "grad_norm": 0.0,
      "learning_rate": 3.6000000000000003e-06,
      "loss": 0.0,
      "step": 205000
    },
    {
      "epoch": 16.44,
      "grad_norm": 0.0,
      "learning_rate": 3.5600000000000002e-06,
      "loss": 0.0,
      "step": 205500
    },
    {
      "epoch": 16.48,
      "grad_norm": 0.0,
      "learning_rate": 3.52e-06,
      "loss": 0.0,
      "step": 206000
    },
    {
      "epoch": 16.52,
      "grad_norm": 0.0,
      "learning_rate": 3.48e-06,
      "loss": 0.0,
      "step": 206500
    },
    {
      "epoch": 16.56,
      "grad_norm": 0.0,
      "learning_rate": 3.44e-06,
      "loss": 0.0,
      "step": 207000
    },
    {
      "epoch": 16.6,
      "grad_norm": 0.0,
      "learning_rate": 3.4000000000000005e-06,
      "loss": 0.0,
      "step": 207500
    },
    {
      "epoch": 16.64,
      "grad_norm": 0.0,
      "learning_rate": 3.3600000000000004e-06,
      "loss": 0.0,
      "step": 208000
    },
    {
      "epoch": 16.68,
      "grad_norm": 0.0,
      "learning_rate": 3.3200000000000004e-06,
      "loss": 0.0,
      "step": 208500
    },
    {
      "epoch": 16.72,
      "grad_norm": 0.0,
      "learning_rate": 3.2800000000000004e-06,
      "loss": 0.0,
      "step": 209000
    },
    {
      "epoch": 16.76,
      "grad_norm": 0.0,
      "learning_rate": 3.2400000000000003e-06,
      "loss": 0.0,
      "step": 209500
    },
    {
      "epoch": 16.8,
      "grad_norm": 0.0,
      "learning_rate": 3.2000000000000003e-06,
      "loss": 0.0,
      "step": 210000
    },
    {
      "epoch": 16.84,
      "grad_norm": 0.0,
      "learning_rate": 3.1600000000000002e-06,
      "loss": 0.0,
      "step": 210500
    },
    {
      "epoch": 16.88,
      "grad_norm": 0.0,
      "learning_rate": 3.12e-06,
      "loss": 0.0,
      "step": 211000
    },
    {
      "epoch": 16.92,
      "grad_norm": 0.0,
      "learning_rate": 3.08e-06,
      "loss": 0.0,
      "step": 211500
    },
    {
      "epoch": 16.96,
      "grad_norm": 0.0,
      "learning_rate": 3.04e-06,
      "loss": 0.0,
      "step": 212000
    },
    {
      "epoch": 17.0,
      "grad_norm": 0.0,
      "learning_rate": 3e-06,
      "loss": 0.0,
      "step": 212500
    },
    {
      "epoch": 17.04,
      "grad_norm": 0.0,
      "learning_rate": 2.96e-06,
      "loss": 0.0,
      "step": 213000
    },
    {
      "epoch": 17.08,
      "grad_norm": 0.0,
      "learning_rate": 2.92e-06,
      "loss": 0.0,
      "step": 213500
    },
    {
      "epoch": 17.12,
      "grad_norm": 0.0,
      "learning_rate": 2.88e-06,
      "loss": 0.0,
      "step": 214000
    },
    {
      "epoch": 17.16,
      "grad_norm": 0.0,
      "learning_rate": 2.84e-06,
      "loss": 0.0,
      "step": 214500
    },
    {
      "epoch": 17.2,
      "grad_norm": 0.0,
      "learning_rate": 2.8000000000000003e-06,
      "loss": 0.0,
      "step": 215000
    },
    {
      "epoch": 17.24,
      "grad_norm": 0.0,
      "learning_rate": 2.7600000000000003e-06,
      "loss": 0.0,
      "step": 215500
    },
    {
      "epoch": 17.28,
      "grad_norm": 0.0,
      "learning_rate": 2.7200000000000002e-06,
      "loss": 0.0,
      "step": 216000
    },
    {
      "epoch": 17.32,
      "grad_norm": 0.0,
      "learning_rate": 2.68e-06,
      "loss": 0.0,
      "step": 216500
    },
    {
      "epoch": 17.36,
      "grad_norm": 0.0,
      "learning_rate": 2.64e-06,
      "loss": 0.0,
      "step": 217000
    },
    {
      "epoch": 17.4,
      "grad_norm": 0.0,
      "learning_rate": 2.6e-06,
      "loss": 0.0,
      "step": 217500
    },
    {
      "epoch": 17.44,
      "grad_norm": 0.0,
      "learning_rate": 2.56e-06,
      "loss": 0.0,
      "step": 218000
    },
    {
      "epoch": 17.48,
      "grad_norm": 0.0,
      "learning_rate": 2.52e-06,
      "loss": 0.0,
      "step": 218500
    },
    {
      "epoch": 17.52,
      "grad_norm": 0.0,
      "learning_rate": 2.4800000000000004e-06,
      "loss": 0.0,
      "step": 219000
    },
    {
      "epoch": 17.56,
      "grad_norm": 0.0,
      "learning_rate": 2.4400000000000004e-06,
      "loss": 0.0,
      "step": 219500
    },
    {
      "epoch": 17.6,
      "grad_norm": 0.0,
      "learning_rate": 2.4000000000000003e-06,
      "loss": 0.0,
      "step": 220000
    },
    {
      "epoch": 17.64,
      "grad_norm": 0.0,
      "learning_rate": 2.3600000000000003e-06,
      "loss": 0.0,
      "step": 220500
    },
    {
      "epoch": 17.68,
      "grad_norm": 0.0,
      "learning_rate": 2.3200000000000002e-06,
      "loss": 0.0,
      "step": 221000
    },
    {
      "epoch": 17.72,
      "grad_norm": 0.0,
      "learning_rate": 2.28e-06,
      "loss": 0.0,
      "step": 221500
    },
    {
      "epoch": 17.76,
      "grad_norm": 0.0,
      "learning_rate": 2.24e-06,
      "loss": 0.0,
      "step": 222000
    },
    {
      "epoch": 17.8,
      "grad_norm": 0.0,
      "learning_rate": 2.2e-06,
      "loss": 0.0,
      "step": 222500
    },
    {
      "epoch": 17.84,
      "grad_norm": 0.0,
      "learning_rate": 2.16e-06,
      "loss": 0.0,
      "step": 223000
    },
    {
      "epoch": 17.88,
      "grad_norm": 0.0,
      "learning_rate": 2.12e-06,
      "loss": 0.0,
      "step": 223500
    },
    {
      "epoch": 17.92,
      "grad_norm": 0.0,
      "learning_rate": 2.08e-06,
      "loss": 0.0,
      "step": 224000
    },
    {
      "epoch": 17.96,
      "grad_norm": 0.0,
      "learning_rate": 2.04e-06,
      "loss": 0.0,
      "step": 224500
    },
    {
      "epoch": 18.0,
      "grad_norm": 0.0,
      "learning_rate": 2.0000000000000003e-06,
      "loss": 0.0,
      "step": 225000
    },
    {
      "epoch": 18.04,
      "grad_norm": 0.0,
      "learning_rate": 1.9600000000000003e-06,
      "loss": 0.0,
      "step": 225500
    },
    {
      "epoch": 18.08,
      "grad_norm": 0.0,
      "learning_rate": 1.9200000000000003e-06,
      "loss": 0.0,
      "step": 226000
    },
    {
      "epoch": 18.12,
      "grad_norm": 0.0,
      "learning_rate": 1.8800000000000002e-06,
      "loss": 0.0,
      "step": 226500
    },
    {
      "epoch": 18.16,
      "grad_norm": 0.0,
      "learning_rate": 1.8400000000000002e-06,
      "loss": 0.0,
      "step": 227000
    },
    {
      "epoch": 18.2,
      "grad_norm": 0.0,
      "learning_rate": 1.8000000000000001e-06,
      "loss": 0.0,
      "step": 227500
    },
    {
      "epoch": 18.24,
      "grad_norm": 0.0,
      "learning_rate": 1.76e-06,
      "loss": 0.0,
      "step": 228000
    },
    {
      "epoch": 18.28,
      "grad_norm": 0.0,
      "learning_rate": 1.72e-06,
      "loss": 0.0,
      "step": 228500
    },
    {
      "epoch": 18.32,
      "grad_norm": 0.0,
      "learning_rate": 1.6800000000000002e-06,
      "loss": 0.0,
      "step": 229000
    },
    {
      "epoch": 18.36,
      "grad_norm": 0.0,
      "learning_rate": 1.6400000000000002e-06,
      "loss": 0.0,
      "step": 229500
    },
    {
      "epoch": 18.4,
      "grad_norm": 0.0,
      "learning_rate": 1.6000000000000001e-06,
      "loss": 0.0,
      "step": 230000
    },
    {
      "epoch": 18.44,
      "grad_norm": 0.0,
      "learning_rate": 1.56e-06,
      "loss": 0.0,
      "step": 230500
    },
    {
      "epoch": 18.48,
      "grad_norm": 0.0,
      "learning_rate": 1.52e-06,
      "loss": 0.0,
      "step": 231000
    },
    {
      "epoch": 18.52,
      "grad_norm": 0.0,
      "learning_rate": 1.48e-06,
      "loss": 0.0,
      "step": 231500
    },
    {
      "epoch": 18.56,
      "grad_norm": 0.0,
      "learning_rate": 1.44e-06,
      "loss": 0.0,
      "step": 232000
    },
    {
      "epoch": 18.6,
      "grad_norm": 0.0,
      "learning_rate": 1.4000000000000001e-06,
      "loss": 0.0,
      "step": 232500
    },
    {
      "epoch": 18.64,
      "grad_norm": 0.0,
      "learning_rate": 1.3600000000000001e-06,
      "loss": 0.0,
      "step": 233000
    },
    {
      "epoch": 18.68,
      "grad_norm": 0.0,
      "learning_rate": 1.32e-06,
      "loss": 0.0,
      "step": 233500
    },
    {
      "epoch": 18.72,
      "grad_norm": 0.0,
      "learning_rate": 1.28e-06,
      "loss": 0.0,
      "step": 234000
    },
    {
      "epoch": 18.76,
      "grad_norm": 0.0,
      "learning_rate": 1.2400000000000002e-06,
      "loss": 0.0,
      "step": 234500
    },
    {
      "epoch": 18.8,
      "grad_norm": 0.0,
      "learning_rate": 1.2000000000000002e-06,
      "loss": 0.0,
      "step": 235000
    },
    {
      "epoch": 18.84,
      "grad_norm": 0.0,
      "learning_rate": 1.1600000000000001e-06,
      "loss": 0.0,
      "step": 235500
    },
    {
      "epoch": 18.88,
      "grad_norm": 0.0,
      "learning_rate": 1.12e-06,
      "loss": 0.0,
      "step": 236000
    },
    {
      "epoch": 18.92,
      "grad_norm": 0.0,
      "learning_rate": 1.08e-06,
      "loss": 0.0,
      "step": 236500
    },
    {
      "epoch": 18.96,
      "grad_norm": 0.0,
      "learning_rate": 1.04e-06,
      "loss": 0.0,
      "step": 237000
    },
    {
      "epoch": 19.0,
      "grad_norm": 0.0,
      "learning_rate": 1.0000000000000002e-06,
      "loss": 0.0,
      "step": 237500
    },
    {
      "epoch": 19.04,
      "grad_norm": 0.0,
      "learning_rate": 9.600000000000001e-07,
      "loss": 0.0,
      "step": 238000
    },
    {
      "epoch": 19.08,
      "grad_norm": 0.0,
      "learning_rate": 9.200000000000001e-07,
      "loss": 0.0,
      "step": 238500
    },
    {
      "epoch": 19.12,
      "grad_norm": 0.0,
      "learning_rate": 8.8e-07,
      "loss": 0.0,
      "step": 239000
    },
    {
      "epoch": 19.16,
      "grad_norm": 0.0,
      "learning_rate": 8.400000000000001e-07,
      "loss": 0.0,
      "step": 239500
    },
    {
      "epoch": 19.2,
      "grad_norm": 0.0,
      "learning_rate": 8.000000000000001e-07,
      "loss": 0.0,
      "step": 240000
    },
    {
      "epoch": 19.24,
      "grad_norm": 0.0,
      "learning_rate": 7.6e-07,
      "loss": 0.0,
      "step": 240500
    },
    {
      "epoch": 19.28,
      "grad_norm": 0.0,
      "learning_rate": 7.2e-07,
      "loss": 0.0,
      "step": 241000
    },
    {
      "epoch": 19.32,
      "grad_norm": 0.0,
      "learning_rate": 6.800000000000001e-07,
      "loss": 0.0,
      "step": 241500
    },
    {
      "epoch": 19.36,
      "grad_norm": 0.0,
      "learning_rate": 6.4e-07,
      "loss": 0.0,
      "step": 242000
    },
    {
      "epoch": 19.4,
      "grad_norm": 0.0,
      "learning_rate": 6.000000000000001e-07,
      "loss": 0.0,
      "step": 242500
    },
    {
      "epoch": 19.44,
      "grad_norm": 0.0,
      "learning_rate": 5.6e-07,
      "loss": 0.0,
      "step": 243000
    },
    {
      "epoch": 19.48,
      "grad_norm": 0.0,
      "learning_rate": 5.2e-07,
      "loss": 0.0,
      "step": 243500
    },
    {
      "epoch": 19.52,
      "grad_norm": 0.0,
      "learning_rate": 4.800000000000001e-07,
      "loss": 0.0,
      "step": 244000
    },
    {
      "epoch": 19.56,
      "grad_norm": 0.0,
      "learning_rate": 4.4e-07,
      "loss": 0.0,
      "step": 244500
    },
    {
      "epoch": 19.6,
      "grad_norm": 0.0,
      "learning_rate": 4.0000000000000003e-07,
      "loss": 0.0,
      "step": 245000
    },
    {
      "epoch": 19.64,
      "grad_norm": 0.0,
      "learning_rate": 3.6e-07,
      "loss": 0.0,
      "step": 245500
    },
    {
      "epoch": 19.68,
      "grad_norm": 0.0,
      "learning_rate": 3.2e-07,
      "loss": 0.0,
      "step": 246000
    },
    {
      "epoch": 19.72,
      "grad_norm": 0.0,
      "learning_rate": 2.8e-07,
      "loss": 0.0,
      "step": 246500
    },
    {
      "epoch": 19.76,
      "grad_norm": 0.0,
      "learning_rate": 2.4000000000000003e-07,
      "loss": 0.0,
      "step": 247000
    },
    {
      "epoch": 19.8,
      "grad_norm": 0.0,
      "learning_rate": 2.0000000000000002e-07,
      "loss": 0.0,
      "step": 247500
    },
    {
      "epoch": 19.84,
      "grad_norm": 0.0,
      "learning_rate": 1.6e-07,
      "loss": 0.0,
      "step": 248000
    },
    {
      "epoch": 19.88,
      "grad_norm": 0.0,
      "learning_rate": 1.2000000000000002e-07,
      "loss": 0.0,
      "step": 248500
    },
    {
      "epoch": 19.92,
      "grad_norm": 0.0,
      "learning_rate": 8e-08,
      "loss": 0.0,
      "step": 249000
    },
    {
      "epoch": 19.96,
      "grad_norm": 0.0,
      "learning_rate": 4e-08,
      "loss": 0.0,
      "step": 249500
    },
    {
      "epoch": 20.0,
      "grad_norm": 0.0,
      "learning_rate": 0.0,
      "loss": 0.0,
      "step": 250000
    }
  ],
  "logging_steps": 500,
  "max_steps": 250000,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 20,
  "save_steps": 10000,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 5.26247294976e+17,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
